import asyncio
import numpy as np
import re
from typing import Dict, List, Optional
from collections import defaultdict
from bleak import BleakClient, BleakScanner
import os
from datetime import datetime


# =========================================================
# Configuration
# =========================================================

DEVICES = {
    # Device name (Windows) or address (MacOS)
    "user0": "Sender_1",
    "user1": "Sender_2",
}

SERVICE_UUID = "19B10000-E8F2-537E-4F6C-D104768A1214"
NOTIFY_UUID = "19B10001-E8F2-537E-4F6C-D104768A1214"
WRITE_UUID = "19B10002-E8F2-537E-4F6C-D104768A1214"

HEADER_SIZE = 11
FLAG_LAST_CHUNK = 0x01

MAX_CHUNK_PAYLOAD = 180

# ===== FL weight =====
ratio_user1 = 0.5   # user1 weight (user0 = 1 - ratio_user1)

# ===== Global state =====
clients: Dict[str, BleakClient] = {}  # user_id -> BleakClient
round_id = 0  # FL round count
broadcasting = False  # Avoid concurrent broadcasts
broadcast_queue: Optional[asyncio.Queue] = None  # Triggers global weight broadcast (initialized in main)


# =========================================================
# write `.h`
# =========================================================

def write_weights_to_h(weights: np.ndarray, name: str, out_dir="ble_weights"):
    os.makedirs(out_dir, exist_ok=True)
    path = os.path.join(out_dir, f"{name}.h")

    with open(path, "w") as f:
        f.write("// ==========================================\n")
        f.write("// Auto-generated by BLE FL loop\n")
        f.write(f"// Name: {name}\n")
        f.write(f"// Generated at: {datetime.now()}\n")
        f.write("// ==========================================\n\n")

        f.write("#pragma once\n\n")
        f.write(f"#define WEIGHTS_CNT {len(weights)}\n\n")
        f.write("static const float model_weights[WEIGHTS_CNT] = {\n")

        for i, w in enumerate(weights):
            f.write(f"    {w:.8f}f")
            if i != len(weights) - 1:
                f.write(",")
            if (i + 1) % 6 == 0:
                f.write("\n")
            else:
                f.write(" ")

        f.write("\n};\n")

    print(f"üíæ Wrote {path}")


# =========================================================
# Session
# =========================================================

class WeightSession:
    def __init__(self, session_id, total_chunks, total_size):
        self.session_id = session_id
        self.total_chunks = total_chunks
        self.total_size = total_size
        self.chunks = {}

    def add_chunk(self, chunk_id, payload):
        if chunk_id not in self.chunks:
            self.chunks[chunk_id] = payload

    def is_complete(self):
        return len(self.chunks) == self.total_chunks

    def assemble(self):
        data = bytearray()
        for i in range(self.total_chunks):
            data.extend(self.chunks[i])
        return data[:self.total_size]


# =========================================================
# FL pairing scheduler
# =========================================================

class FLState:
    def __init__(self):
        # One queue per user
        # Queues are initialized in main() (requires an event loop)
        self.queues: Optional[Dict[str, asyncio.Queue]] = None

    def add(self, user_id: str, weights: np.ndarray, session_id: int):
        """
        Add a local model update to corresponding user's queue.
        `session_id` is used to tag the update (which round).
        """
        if self.queues is None:
            print("‚ö†Ô∏è FLState queues not initialized")
            return

        self.queues[user_id].put_nowait((session_id, weights))
        print(f"üß© [{user_id}] Weights added to queue (session={session_id}), queue length={self.queues[user_id].qsize()}")

    async def try_aggregate(self) -> Optional[np.ndarray]:
        """
        if both queues are non-empty:
            -> perform pairing + aggregation
            -> return ndarray
        else:
            -> wait
            -> return None
        """
        if self.queues is None:
            return None

        # check if empty
        if self.queues["user0"].empty() or self.queues["user1"].empty():
            return None

        try:
            sid0, w0 = self.queues["user0"].get_nowait()
            sid1, w1 = self.queues["user1"].get_nowait()

            print(f"üîó Matched for aggregation: user0(session={sid0}) + user1(session={sid1})")

            # perform FedAvg
            w = (1 - ratio_user1) * w0 + ratio_user1 * w1

            return w

        except asyncio.QueueEmpty:
            return None


fl_state = FLState()


# =========================================================
# Packetize weights for distribution
# =========================================================

def pack_weights(weights: np.ndarray, session_id: int = 1) -> List[bytes]:

    data = weights.astype(np.float32).tobytes()
    total_size = len(data)

    # compute chunks
    total_chunks = (total_size + MAX_CHUNK_PAYLOAD - 1) // MAX_CHUNK_PAYLOAD
    packets: List[bytes] = []

    print(f"üì¶ Packing weights: total_size={total_size} bytes, chunks={total_chunks}")

    offset = 0
    for chunk_id in range(total_chunks):
        last = (chunk_id == total_chunks - 1)
        payload = data[offset : offset + MAX_CHUNK_PAYLOAD]
        offset += len(payload)

        flags = FLAG_LAST_CHUNK if last else 0

        header = bytes(
            [
                (session_id >> 8) & 0xFF,
                session_id & 0xFF,
                (chunk_id >> 8) & 0xFF,
                chunk_id & 0xFF,
                (total_chunks >> 8) & 0xFF,
                total_chunks & 0xFF,
                (total_size >> 24) & 0xFF,
                (total_size >> 16) & 0xFF,
                (total_size >> 8) & 0xFF,
                total_size & 0xFF,
                flags,
            ]
        )

        packets.append(header + payload)

    return packets


# =========================================================
# Distribute GlobalWeights back to all connected MCUs
# =========================================================

async def broadcast_global(global_w: np.ndarray):
    """
    Broadcast global model to all connected clients.
    Manage round-level state.
    """
    global broadcasting, round_id

    if broadcasting:
        print("‚ö†Ô∏è Transmission in progress, skipping this request")
        return

    broadcasting = True
    round_id += 1

    try:
        print(f"\nüåç ===== Round {round_id}: Broadcasting Global Weights =====")
        write_weights_to_h(global_w, f"global_fedavg_round{round_id}")

        packets = pack_weights(global_w, session_id=round_id)

        tasks = []
        for user_id, client in clients.items():
            if client.is_connected:
                tasks.append(push_to_client(user_id, client, packets))

        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
        else:
            print("‚ö†Ô∏è No device connected")

        print(f"üåç ===== Round {round_id} Complete =====\n")

    except Exception as e:
        print(f"‚ùå Broadcast failed: {e}")
    finally:
        broadcasting = False


async def push_to_client(user_id: str, client: BleakClient, packets: List[bytes]):
    """
    Transmit a complete set of chucks to single client.
    """
    try:
        print(f"üì§ [{user_id}] Start sending global weights back to device...")

        for i, pkt in enumerate(packets):
            await client.write_gatt_char(WRITE_UUID, pkt, response=True)
            await asyncio.sleep(0.02)

            if (i + 1) % 10 == 0 or i == len(packets) - 1:
                print(f"  [{user_id}] Sent chunk {i+1}/{len(packets)}")

        print(f"‚úÖ [{user_id}] Global weights written successfully")

    except Exception as e:
        print(f"‚ö†Ô∏è [{user_id}] Failed to write global weights: {e}")


# =========================================================
# Aggregator (1 for each client)
# =========================================================

class BLEAggregator:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.sessions = {}

    def handle_packet(self, data: bytes):
        if len(data) < HEADER_SIZE:
            return

        session_id = (data[0] << 8) | data[1]
        chunk_id = (data[2] << 8) | data[3]
        total_chunks = (data[4] << 8) | data[5]
        total_size = (
            (data[6] << 24) |
            (data[7] << 16) |
            (data[8] << 8)  |
            data[9]
        )

        payload = data[HEADER_SIZE:]

        if session_id not in self.sessions:
            print(f"\nüÜï [{self.user_id}] Session {session_id}")
            self.sessions[session_id] = WeightSession(
                session_id, total_chunks, total_size
            )

        session = self.sessions[session_id]
        session.add_chunk(chunk_id, payload)

        print(
            f"[{self.user_id}] "
            f"chunk {chunk_id+1}/{total_chunks} "
            f"({len(payload)} bytes)"
        )

        if session.is_complete():
            print(f"‚úÖ [{self.user_id}] Session {session_id} COMPLETE")

            asyncio.create_task(self.on_complete(session))
            del self.sessions[session_id]

    async def on_complete(self, session: WeightSession):
        raw = session.assemble()
        weights = np.frombuffer(raw, dtype=np.float32)

        print(f"üî¢ [{self.user_id}] weights shape = {weights.shape}")
        write_weights_to_h(weights, f"{self.user_id}_local")

        # Add local update to FL queues
        fl_state.add(self.user_id, weights, session.session_id)

        # Try pairwise aggregation if both queues have data
        if broadcast_queue is not None:
            try:
                global_w = await fl_state.try_aggregate()
                if global_w is not None:
                    print("\nüåç Running Federated Averaging")
                    write_weights_to_h(global_w, "global_fedavg")
                    print("üåç FedAvg DONE")

                    # Trigger broadcast of global model
                    broadcast_queue.put_nowait(global_w)
                else:
                    print(f"‚è≥ [{self.user_id}] Waiting for the other user's weights...")
            except Exception as e:
                print(f"‚ö†Ô∏è Aggregation error: {e}")
        else:
            print("‚ö†Ô∏è Broadcast queue not initialized")


# =========================================================
# BLE connection + FL control loop
# =========================================================

async def resolve_identifier(identifier: str) -> str:
    """
    identifier:
      - if already looks like an address ('-'), return directly,
      - Or, scan once by device name & return the resolved address.
    """
    if "-" in identifier:
        return identifier

    print(f"üîç Scanning for device name: {identifier}")
    devices = await BleakScanner.discover(timeout=5.0)
    for d in devices:
        if d.name == identifier:
            print(f"‚úÖ Found device {identifier}: {d.address}")
            return d.address

    raise RuntimeError(f"Device  {identifier} not found (name scan)")


async def connect_device(user_id: str, identifier: str):
    """
    Connect to BLE device and continuously listen for model updates.
    """
    global clients

    while True:
        try:
            addr = await resolve_identifier(identifier)
            print(f"üîó [{user_id}] Connecting to {identifier} ({addr})")

            async with BleakClient(addr) as client:
                clients[user_id] = client
                print(f"‚úÖ [{user_id}] successfully connected!")

                aggregator = BLEAggregator(user_id)

                def handler(_, data):
                    aggregator.handle_packet(bytes(data))

                await client.start_notify(NOTIFY_UUID, handler)
                print(f"üì° [{user_id}] Listening for weight updates...")

                # Keep the connection alive
                while client.is_connected:
                    await asyncio.sleep(1)

        except Exception as e:
            print(f"‚ö†Ô∏è [{user_id}] connection error: {e}")
            if user_id in clients:
                del clients[user_id]

        print(f"üîÑ [{user_id}] Reconnecting in 5 seconds...")
        await asyncio.sleep(5)


async def broadcast_worker():
    """
    Background task:
    pull global weights from the queue,
    broadcast to all connected devices.
    """
    while True:
        try:
            global_w = await broadcast_queue.get()
            await broadcast_global(global_w)
            broadcast_queue.task_done()
        except Exception as e:
            print(f"‚ùå Broadcast worker error: {e}")


async def main():
    global broadcast_queue

    print("=" * 60)
    print("BLE-based FL loop")
    print("=" * 60)
    print(f"Target devices: {list(DEVICES.keys())}")
    print("=" * 60)
    print()

    # initialize queue
    broadcast_queue = asyncio.Queue()
    
    # initialize queue of FLState
    fl_state.queues = {
        "user0": asyncio.Queue(),
        "user1": asyncio.Queue(),
    }

    # Start background broadcast worker
    asyncio.create_task(broadcast_worker())

    # Connect to all devices concurrently
    tasks = [
        connect_device(user_id, identifier)
        for user_id, identifier in DEVICES.items()
    ]

    await asyncio.gather(*tasks, return_exceptions=True)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüõë FL Terminated.")

